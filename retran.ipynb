{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76b70ad0",
   "metadata": {},
   "source": [
    "# Attention Ain't All, Recurent Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f5287",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7564a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, math, torch, time, torchtune, datasets, sys, os, json\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from pysat.solvers import Solver\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a92be0",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac0a44c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = 512 * 1000\n",
    "valid_samples = train_samples // 5\n",
    "test_samples = train_samples // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe44d82-3eff-4f8c-97da-e6aaca8f88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "START = '<start>'\n",
    "STOP = '<stop>'\n",
    "PAD = '<pad>'\n",
    "SEP = '='\n",
    "\n",
    "# Translates from a string to a pytorch tensor using a vocab\n",
    "def encode(string, vocab, pad_length):\n",
    "    out = []\n",
    "    while len(string) > 0:\n",
    "        vocab_match = False\n",
    "        for i in range(1, len(string) + 1):\n",
    "            if string[:i] in vocab:\n",
    "                out.append(vocab.index(string[:i]))\n",
    "                string = string[i:]\n",
    "                vocab_match = True\n",
    "                break\n",
    "        if not vocab_match:\n",
    "            raise Exception(\"Encoding error:\", string, vocab)\n",
    "    out += [vocab.index(PAD)] * (pad_length - len(out))\n",
    "    return torch.tensor(out, dtype=torch.long)\n",
    "\n",
    "# Translates from a pytorch tensor to a string using a vocab\n",
    "def decode(tensor, vocab):\n",
    "    ans = \"\"\n",
    "    for i in tensor:\n",
    "        if vocab[i] == START or vocab[i] == PAD:\n",
    "            continue\n",
    "        if vocab[i] == STOP:\n",
    "            break\n",
    "        ans += vocab[i]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "957b2d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmetic dataset generated using probablistic context free grammar\n",
    "# Consists of integers, +, -, *, //, and %\n",
    "class ArithDataset(torch.utils.data.Dataset):\n",
    "    vocab = [START, SEP, STOP, PAD] + [str(i) for i in range(10)] + ['-', '+', '*',  '%', '//', '(', ')']\n",
    "\n",
    "    # Probablistic context free grammar rules\n",
    "    # Dictionary where key is the token to be expanded and\n",
    "    # right side is list of tuples containing rules and associated probabilities\n",
    "    rules = {\n",
    "        'EQ': [(['VAL', 'OP', 'VAL'], 0.5), (['(', 'VAL', 'OP', 'VAL', ')'], 0.5)],\n",
    "        'VAL': [(['EQ'], 0.45), (['NUM'], 0.55)],\n",
    "        'OP': [(['-'], 0.2), (['+'], 0.2), (['*'], 0.2), (['%'], 0.2), (['//'], 0.2)],\n",
    "        'NUM': [([str(i), 'NUMT'], 1.0/19) for i in range(1, 10)] + [(['-', str(i), 'NUMT'], 1.0/19) for i in range(1, 10)] + [(['0'], 1.0/19)],\n",
    "        'NUMT': [([str(i), 'NUMT'], 0.2/10) for i in range(10)] + [([], 0.8)],\n",
    "    }\n",
    "\n",
    "    # Chooses a rule based on the probabilities\n",
    "    def selectRule(left_hand):\n",
    "        selector = random.random()\n",
    "        for i in ArithDataset.rules[left_hand]:\n",
    "            selector -= i[1]\n",
    "            if(selector < 0):\n",
    "                return i[0]\n",
    "        raise Exception(\"Improper rule probabilities\")\n",
    "\n",
    "    # Initialize dataset with certain bounds\n",
    "    # Bounds relate to the number of tokens, not characters\n",
    "    # X relates to the arithmetic problem, Y the solution\n",
    "    def __init__(self, samples, seed=0, min_x_len=5, max_x_len=30, min_y_len=1, max_y_len=8):\n",
    "        self.min_x_len = min_x_len\n",
    "        self.max_x_len = max_x_len\n",
    "        self.min_y_len = min_y_len\n",
    "        self.max_y_len = max_y_len\n",
    "        \n",
    "        dup_check = set()\n",
    "        self.xy = []\n",
    "        \n",
    "        random.seed(seed)\n",
    "        while (len(dup_check) < samples):\n",
    "            x, y = self.generateProblem()\n",
    "            if x not in dup_check:\n",
    "                if len(dup_check) % 100 == 0:\n",
    "                    sys.stdout.write(f\"\\r {len(dup_check) / samples * 100:.2f}% complete\")\n",
    "                    sys.stdout.flush()\n",
    "                self.xy.append(encode(START + x + SEP + y + STOP, self.vocab, max_x_len + max_y_len))\n",
    "                dup_check.add(x)\n",
    "        print(\"\\r100.00% complete\")\n",
    "        \n",
    "        self.xy = torch.stack(self.xy)\n",
    "        self.x_lens = (self.xy == self.vocab.index(SEP)).nonzero()[:, 1] + 1\n",
    "        self.xy_lens = (self.xy == self.vocab.index(STOP)).nonzero()[:, 1] + 1\n",
    "\n",
    "        # Trim the max length\n",
    "        self.xy = self.xy[:, :torch.max(self.xy_lens)]\n",
    "\n",
    "    # Generate a problem using the context free grammar within dataset bounds\n",
    "    def generateProblem(self):\n",
    "        while(True):\n",
    "            stack = ['EQ']\n",
    "            index = 0\n",
    "            while (index < len(stack) and len(stack) <= (self.max_x_len - 2)): # Subtract 2 for start and sep token\n",
    "                if stack[index] in ArithDataset.rules:\n",
    "                    stack = stack[:index] + ArithDataset.selectRule(stack[index]) + stack[index + 1:]\n",
    "                else:\n",
    "                    index += 1\n",
    "\n",
    "            if len(stack) > (self.max_x_len - 2) or len(stack) < (self.min_x_len - 2):\n",
    "                continue\n",
    "            \n",
    "            try: # Catch division or modulus by 0\n",
    "                x = ''.join(stack)\n",
    "                y = str(eval(x))\n",
    "                if (len(y) >= (self.min_y_len - 1) and len(y) <= (self.max_y_len - 1)): # Subtract 1 for stop token\n",
    "                    return x, y\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def save(self, filename):\n",
    "        torch.save({attr:getattr(self, attr) for attr in ['min_x_len', 'max_x_len', 'min_y_len', 'max_y_len', 'xy', 'x_lens', 'xy_lens']}, filename)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        obj = object.__new__(cls)\n",
    "        obj_data = torch.load(filename)\n",
    "        for attr in obj_data:\n",
    "            setattr(obj, attr, obj_data[attr])\n",
    "        return obj\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.xy)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.xy[idx], self.x_lens[idx], self.xy_lens[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45dd8664-c07f-43de-bbc1-4f6f7be0e30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved arithmetic dataset\n",
      "Arithmetic Problems:\n",
      "(8*(-9+-3//-7))=-72\n",
      "-9*-9*5=405\n",
      "(((1//4+-7)-(3%-7))//-3)=1\n",
      "(((-14//-8)//8+-8)*-3)=24\n",
      "(-9--1)=-8\n",
      "-91-79-(-7-0--8)=-171\n",
      "98*-1=-98\n",
      "5-72=-67\n",
      "7+-4=3\n",
      "(19+8*8-(-2//6)//-79)=83\n",
      "(3%((-9//(-4//8))+17%7))=3\n",
      "(6+2+-1//9%-9+-434)-9*9=-508\n",
      "(4*-1)=-4\n",
      "(-4--3)=-1\n",
      "-7//-7=1\n",
      "(1//23--73+(30--895))=998\n",
      "2*7=14\n",
      "0%(-7+9)=0\n",
      "3%40=3\n",
      "(19--9)=28\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"arith_dataset.pt\"):\n",
    "    print(\"Loading saved arithmetic dataset\")\n",
    "    arithData = ArithDataset.load(\"arith_dataset.pt\")\n",
    "else:\n",
    "    print(\"Generating arithmetic dataset\")\n",
    "    arithData = ArithDataset(train_samples + valid_samples + test_samples)\n",
    "    arithData.save('arith_dataset.pt')\n",
    "arithSets = torch.utils.data.random_split(arithData, [train_samples, valid_samples, test_samples], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "print(\"Arithmetic Problems:\")\n",
    "for i in range(20):\n",
    "    print(decode(arithData[i][0], arithData.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ed0735-4dd0-4aa0-ae2d-219a651c7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer to hexadecimal dataset\n",
    "class HexDataset(torch.utils.data.Dataset):\n",
    "    vocab = [START, SEP, STOP, PAD] + [str(i) for i in range(10)] + ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "\n",
    "    # Initialize dataset with certain bounds\n",
    "    # We generate numbers on an exponential scale to get variety of lengths and difficulties\n",
    "    def __init__(self, samples, seed=0, min_exp=0, max_exp=10):\n",
    "        self.min_exp = min_exp\n",
    "        self.max_exp = max_exp\n",
    "        \n",
    "        dup_check = set()\n",
    "        self.xy = []\n",
    "\n",
    "        max_len = len(str(int(10 ** max_exp))) + len(hex(int(10 ** max_exp))[2:]) + 3 # Crop out 0x, add 3 for start, sep, stop\n",
    "        \n",
    "        random.seed(seed)\n",
    "        while (len(dup_check) < samples):\n",
    "            x = int(10 ** ((max_exp - min_exp) * random.random() + min_exp))\n",
    "            if x not in dup_check:\n",
    "                if len(dup_check) % 100 == 0:\n",
    "                    sys.stdout.write(f\"\\r {len(dup_check) / samples * 100:.2f}% complete\")\n",
    "                    sys.stdout.flush()\n",
    "                self.xy.append(encode(START + str(x) + SEP + hex(x)[2:] + STOP, self.vocab, max_len))\n",
    "                dup_check.add(x)\n",
    "        print(\"\\r100.00% complete\")\n",
    "        \n",
    "        self.xy = torch.stack(self.xy)\n",
    "        self.x_lens = (self.xy == self.vocab.index(SEP)).nonzero()[:, 1] + 1\n",
    "        self.xy_lens = (self.xy == self.vocab.index(STOP)).nonzero()[:, 1] + 1\n",
    "\n",
    "        # Trim the max length\n",
    "        self.xy = self.xy[:, :torch.max(self.xy_lens)]\n",
    "\n",
    "    def save(self, filename):\n",
    "        torch.save({attr:getattr(self, attr) for attr in ['min_exp', 'max_exp', 'xy', 'x_lens', 'xy_lens']}, filename)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        obj = object.__new__(cls)\n",
    "        obj_data = torch.load(filename)\n",
    "        for attr in obj_data:\n",
    "            setattr(obj, attr, obj_data[attr])\n",
    "        return obj\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xy)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.xy[idx], self.x_lens[idx], self.xy_lens[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c00886f6-00a6-4e99-b357-7591a58204a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved hex dataset\n",
      "Hex Problems:\n",
      "278111223=1093a3f7\n",
      "37979044=24383a4\n",
      "16058=3eba\n",
      "388=184\n",
      "129642=1fa6a\n",
      "11203=2bc3\n",
      "68862992=41ac410\n",
      "1079=437\n",
      "58340=e3e4\n",
      "682056=a6848\n",
      "1205393518=47d8d86e\n",
      "111395=1b323\n",
      "658=292\n",
      "36144485=2278565\n",
      "1526475=174acb\n",
      "319=13f\n",
      "1251591369=4a99c4c9\n",
      "6727516326=190fdc0a6\n",
      "126523838=78a99be\n",
      "1051137437=3ea7159d\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"hex_dataset.pt\"):\n",
    "    print(\"Loading saved hex dataset\")\n",
    "    hexData = HexDataset.load(\"hex_dataset.pt\")\n",
    "else:\n",
    "    print(\"Generating hex dataset\")\n",
    "    hexData = HexDataset(train_samples + valid_samples + test_samples)\n",
    "    hexData.save(\"hex_dataset.pt\")\n",
    "hexSets = torch.utils.data.random_split(hexData, [train_samples, valid_samples, test_samples], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "print(\"Hex Problems:\")\n",
    "for i in range(20):\n",
    "    print(decode(hexData[i][0], hexData.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a50a5e8-e6c7-4e32-b908-c0c860658134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a randomized cnf 3sat problem with specific count of clauses and variables\n",
    "def generate3Sat(n_clauses, n_vars):\n",
    "    # Sets to remove duplicate clauses\n",
    "    clauses = set()\n",
    "    while len(clauses) < n_clauses:\n",
    "        clauses.add(frozenset([i if random.random() > 0.5 else -i for i in random.sample(range(1, n_vars + 1), 3)]))\n",
    "    # Check every variable is included at least once\n",
    "    for var in range(1, n_vars + 1):\n",
    "        if sum([var in clause for clause in clauses]) == 0:\n",
    "            return generate3Sat(n_clauses, n_vars)\n",
    "    return tuple(tuple(random.sample(list(clause), 3)) for clause in random.sample(list(clauses), n_clauses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b3f6305-3351-49fe-a916-2fa4e9816fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset of 3-sat problems where the model predicts wether or not the problem is sat\n",
    "class SatSolveDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples, seed=0, n_vars=5):\n",
    "        if n_vars < 4:\n",
    "            raise Exception(\"Must have more than 4 vars\")\n",
    "        self.n_vars = n_vars\n",
    "        # Spaces after numbers to break ambiguity when n_vars > 9\n",
    "        self.vocab = [START, SEP, STOP, PAD] + [f'{i} ' for i in range(1, n_vars + 1)] + [f'{-i} ' for i in range(1, n_vars + 1)] + [', ', 'sat', 'unsat']\n",
    "\n",
    "        dup_check = set()\n",
    "        self.xy = []\n",
    "\n",
    "        # Max vars = num vars * max clauses per var * tokens per clause + sep, soln, stop (stop is trivial, but used in solve function later)\n",
    "        max_len = n_vars * 5 * 4 + 3\n",
    "        while (len(dup_check) < samples):\n",
    "            # The hardest satisfiability problems occur when there are ~ 4.26 clauses per variable\n",
    "            # to create consistently hard problems with some variation, we generate problems where there are\n",
    "            # between 4 and 5 clauses per variable\n",
    "            n_clauses = random.randint(n_vars * 4, n_vars * 5)\n",
    "            x = generate3Sat(n_clauses, n_vars)\n",
    "            if x not in dup_check:\n",
    "                if len(dup_check) % 100 == 0:\n",
    "                    sys.stdout.write(f\"\\r {len(dup_check) / samples * 100:.2f}% complete\")\n",
    "                    sys.stdout.flush()\n",
    "                with Solver(name='g3') as solver:\n",
    "                    for clause in x:\n",
    "                        solver.add_clause(clause)\n",
    "                    satisfiable = solver.solve()\n",
    "                if satisfiable:\n",
    "                    self.xy.append(encode(START + ', '.join(''.join(f'{var} ' for var in clause) for clause in x) + SEP + 'sat' + STOP, self.vocab, max_len))\n",
    "                else:\n",
    "                    self.xy.append(encode(START + ', '.join(''.join(f'{var} ' for var in clause) for clause in x) + SEP + 'unsat' + STOP, self.vocab, max_len))\n",
    "                dup_check.add(x)\n",
    "        print(\"\\r100.00% complete\")\n",
    "\n",
    "        self.xy = torch.stack(self.xy)\n",
    "        self.x_lens = (self.xy == self.vocab.index(SEP)).nonzero()[:, 1] + 1\n",
    "        self.xy_lens = (self.xy == self.vocab.index(STOP)).nonzero()[:, 1] + 1\n",
    "\n",
    "        # Trim the max length\n",
    "        self.xy = self.xy[:, :torch.max(self.xy_lens)]\n",
    "\n",
    "    def save(self, filename):\n",
    "        torch.save({attr:getattr(self, attr) for attr in ['n_vars', 'vocab', 'xy', 'x_lens', 'xy_lens']}, filename)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        obj = object.__new__(cls)\n",
    "        obj_data = torch.load(filename)\n",
    "        for attr in obj_data:\n",
    "            setattr(obj, attr, obj_data[attr])\n",
    "        return obj\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.xy)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.xy[idx], self.x_lens[idx], self.xy_lens[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c2e00cc-cc02-40cd-b309-c06cf2b7708c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved sat solve dataset\n",
      "Satisfiability Solver Problems:\n",
      "-5 -2 -1 , 3 -2 4 , 1 -2 4 , -4 1 3 , -5 1 -3 , -2 -1 5 , 4 -3 1 , -4 5 2 , 1 5 2 , -4 -5 3 , 2 -1 5 , -3 -2 4 , -5 -1 -4 , 2 4 -1 , -4 5 -2 , -1 -2 4 , 4 -5 -3 , 5 -3 4 , 5 2 4 , 5 -1 3 , 1 -2 5 , -3 -1 5 =sat\n",
      "2 -1 -5 , -1 5 3 , -4 -1 5 , -5 -2 -1 , -1 4 2 , -5 2 1 , 5 -2 3 , 4 -2 -3 , -1 4 -3 , 2 4 -5 , 2 1 3 , 2 1 -3 , 5 2 3 , -1 2 3 , -2 -4 1 , 2 4 3 , -3 -2 5 , 4 -2 3 , -1 -2 5 , 3 -1 -4 , 3 -5 4 =unsat\n",
      "3 -1 4 , 4 1 -3 , 4 -1 -5 , -1 -5 -3 , 5 3 1 , -2 4 -3 , -5 2 -1 , -1 5 -3 , 3 4 1 , -2 -1 4 , 1 -4 -2 , -4 -5 -3 , -4 2 1 , -2 1 -5 , -2 -3 -5 , -3 -1 4 , 2 -5 -3 , 2 -1 3 , 1 5 2 , 5 -4 3 , -2 5 -3 , -2 -5 -4 , -1 -4 -2 =unsat\n",
      "5 2 1 , -2 -5 -3 , 4 -3 1 , -5 2 1 , 1 -3 -5 , 4 3 2 , -2 3 -4 , -1 -2 5 , -2 5 -4 , 4 5 1 , -5 3 2 , -2 1 -4 , 5 -3 -2 , 2 1 3 , -1 -3 -2 , -1 2 3 , 3 4 -5 , 5 4 -3 , 5 -3 -4 , -2 4 5 , -5 2 -3 , 5 2 -1 , 5 2 4 , 5 -1 -3 , -1 -2 3 =unsat\n",
      "4 5 3 , 1 2 -4 , 1 3 2 , -5 -3 2 , -1 -3 2 , -4 5 1 , 2 3 -4 , -2 3 1 , 1 -5 3 , -2 1 5 , -4 5 -1 , 5 3 2 , -1 -3 5 , 5 -1 3 , -1 3 2 , 3 4 -1 , 3 -4 -5 , 3 1 -4 , -1 -3 4 , 5 1 3 , 4 3 1 , -2 -4 -3 , 2 -5 3 =sat\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"sat_solve_dataset.pt\"):\n",
    "    print(\"Loading saved sat solve dataset\")\n",
    "    satSolveData = SatSolveDataset.load(\"sat_solve_dataset.pt\")\n",
    "else:\n",
    "    print(\"Generating sat solve dataset\")\n",
    "    satSolveData = SatSolveDataset(train_samples + valid_samples + test_samples)\n",
    "    satSolveData.save('sat_solve_dataset.pt')\n",
    "satSolveSets = torch.utils.data.random_split(satSolveData, [train_samples, valid_samples, test_samples], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "print(\"Satisfiability Solver Problems:\")\n",
    "for i in range(5):\n",
    "    print(decode(satSolveData[i][0], satSolveData.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7ac8e7d-1549-48e5-b790-dbb86cc5ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset of 3-sat problems where the model predicts the one sat solution\n",
    "class SingleSatDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples, seed=0, n_vars=6):\n",
    "        if n_vars < 4:\n",
    "            raise Exception(\"Must have more than 4 vars\")\n",
    "        self.n_vars = n_vars\n",
    "        # Spaces after numbers to break ambiguity when n_vars > 9\n",
    "        self.vocab = [START, SEP, STOP, PAD] + [f'{i} ' for i in range(1, n_vars + 1)] + [f'{-i} ' for i in range(1, n_vars + 1)] + [', ', 'True', 'False']\n",
    "\n",
    "        dup_check = set()\n",
    "        self.xy = []\n",
    "\n",
    "        # Max vars = num vars * max clauses per var * tokens per clause + sep, soln, stop\n",
    "        max_len = n_vars * 5 * 4 + n_vars + 2\n",
    "        while (len(dup_check) < samples):\n",
    "            # The hardest satisfiability problems occur when there are ~ 4.26 clauses per variable\n",
    "            # to create consistently hard problems with some variation, we generate problems where there are\n",
    "            # between 4 and 5 clauses per variable\n",
    "            n_clauses = random.randint(n_vars * 4, n_vars * 5)\n",
    "            x = generate3Sat(n_clauses, n_vars)\n",
    "            if x not in dup_check:\n",
    "                with Solver(name='g3') as solver:\n",
    "                    for clause in x:\n",
    "                        solver.add_clause(clause)\n",
    "                    if not solver.solve():\n",
    "                        continue\n",
    "                    model = solver.get_model()\n",
    "                    blocking_clause = [-lit for lit in model]\n",
    "                    solver.add_clause(blocking_clause)\n",
    "                    if solver.solve():\n",
    "                        continue\n",
    "                    self.xy.append(encode(START + ', '.join(''.join(f'{var} ' for var in clause) for clause in x) + SEP + ''.join([str(i>0) for i in model]) + STOP, self.vocab, max_len))\n",
    "                if len(dup_check) % 100 == 0:\n",
    "                    sys.stdout.write(f\"\\r {len(dup_check) / samples * 100:.2f}% complete\")\n",
    "                    sys.stdout.flush()\n",
    "                dup_check.add(x)\n",
    "        print(\"100.00% complete\")\n",
    "\n",
    "        self.xy = torch.stack(self.xy)\n",
    "        self.x_lens = (self.xy == self.vocab.index(SEP)).nonzero()[:, 1] + 1\n",
    "        self.xy_lens = (self.xy == self.vocab.index(STOP)).nonzero()[:, 1] + 1\n",
    "\n",
    "        # Trim the max length\n",
    "        self.xy = self.xy[:, :torch.max(self.xy_lens)]\n",
    "\n",
    "    def save(self, filename):\n",
    "        torch.save({attr:getattr(self, attr) for attr in ['n_vars', 'vocab', 'xy', 'x_lens', 'xy_lens']}, filename)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        obj = object.__new__(cls)\n",
    "        obj_data = torch.load(filename)\n",
    "        for attr in obj_data:\n",
    "            setattr(obj, attr, obj_data[attr])\n",
    "        return obj\n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.xy)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.xy[idx], self.x_lens[idx], self.xy_lens[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0a18429-3360-4d17-bb47-0d3bb7bb97da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved single sat dataset\n",
      "Single Satisfiable Problems:\n",
      "4 3 6 , -4 -3 -2 , 3 -6 -4 , -1 2 -4 , -1 2 3 , 2 6 3 , 2 4 1 , -2 4 -1 , -6 3 5 , 3 1 -5 , 1 -3 -6 , -2 6 -1 , 4 -1 -6 , -2 1 6 , 6 -3 -4 , 5 -3 2 , -2 -6 -4 , 1 6 4 , -3 -2 -1 , -2 -3 -5 , 1 -6 3 , -1 -6 3 , -5 -3 1 , -3 -6 -4 =TrueFalseTrueFalseTrueFalse\n",
      "4 1 5 , 6 2 3 , 4 -6 -3 , 3 -5 -1 , -4 -2 -3 , 5 -4 -6 , -6 -1 4 , 4 6 5 , 2 6 5 , 4 -3 -5 , 5 3 1 , 6 -3 -4 , -4 -6 2 , -4 -3 5 , -5 6 -4 , -2 5 -1 , 2 -6 4 , -6 5 -2 , -1 2 3 , -6 4 3 , -5 1 2 , 1 -5 4 , -2 6 3 , 6 1 -2 =FalseTrueFalseTrueTrueTrue\n",
      "1 -6 -4 , 2 -5 4 , -5 -2 -1 , -1 6 -3 , -3 1 -4 , -4 2 -1 , 1 5 4 , -3 6 1 , 4 -6 -5 , -6 -5 1 , -4 2 1 , -3 5 2 , 2 -4 -6 , 3 2 6 , 4 3 -2 , -1 2 -6 , 4 1 2 , -2 -6 -5 , 5 6 -2 , -3 -5 -2 , -2 -1 -3 , -1 2 5 , 3 -2 1 , -6 -1 -3 =TrueTrueFalseTrueFalseTrue\n",
      "-2 -6 -3 , 6 5 -2 , -2 5 -3 , 4 1 -3 , 3 2 4 , -6 5 -1 , -5 -2 -6 , 5 -1 4 , 4 5 -3 , -1 -2 4 , -5 2 -6 , -6 -5 -3 , 1 2 -6 , 5 -1 2 , -5 4 -6 , 6 -4 -5 , -4 -6 -2 , -2 5 -6 , 4 -6 -3 , -3 -1 -2 , 4 -6 2 , -3 6 2 , -6 -1 -5 , -3 -6 2 , 6 4 -2 , -2 -5 3 , 1 3 -5 , 3 -2 1 , -5 -3 -1 =FalseFalseFalseTrueFalseFalse\n",
      "2 1 -4 , -4 -5 -6 , 5 -1 2 , 1 6 5 , 2 -5 6 , -4 5 1 , 3 4 1 , 5 1 -2 , 4 3 -1 , -6 -5 -2 , -3 -6 2 , -5 -3 -1 , -4 1 6 , 3 -5 -6 , -3 -2 4 , 6 -1 4 , 6 -1 -3 , 2 4 -3 , -2 -4 1 , 3 2 6 , 2 1 4 , -5 2 -1 , -3 6 -5 , -4 -5 3 , 3 -1 -4 =TrueTrueTrueTrueFalseTrue\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"single_sat_dataset.pt\"):\n",
    "    print(\"Loading saved single sat dataset\")\n",
    "    singleSatData = SingleSatDataset.load(\"single_sat_dataset.pt\")\n",
    "else:\n",
    "    print(\"Generating single sat dataset\")\n",
    "    singleSatData = SingleSatDataset(train_samples + valid_samples + test_samples)\n",
    "    singleSatData.save(\"single_sat_dataset.pt\")\n",
    "singleSatSets = torch.utils.data.random_split(singleSatData, [train_samples, valid_samples, test_samples], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "print(\"Single Satisfiable Problems:\")\n",
    "for i in range(5):\n",
    "    print(decode(singleSatData[i][0], singleSatData.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e93880",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "597cd48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic feed forward, uses GELU activation and GPT-2 initialization\n",
    "class FeedFwd(nn.Module):\n",
    "    def __init__(self, dims, dropout=0.1, activ=nn.GELU()):\n",
    "        super(FeedFwd, self).__init__()\n",
    "        layers = [nn.Linear(dims[i], dims[i+1]) for i in range(len(dims) - 1)]\n",
    "        for i in layers:\n",
    "            torch.nn.init.normal_(i.weight, mean=0.0, std=0.02)\n",
    "            nn.init.zeros_(i.bias)\n",
    "        self.lays = nn.ModuleList(layers)\n",
    "        self.activ = activ\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.lays[:-1]:\n",
    "            x = self.drop(self.activ(layer(x)))\n",
    "        return self.lays[-1](x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5039894-b147-4d26-a507-64ba939b5967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long short-term memory network with projection\n",
    "# Utilizes orthogonal initialization for recurrent weights and GPT-2 initialization for others\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, d_in, d_long, d_short):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.d_in = d_in\n",
    "        self.d_long = d_long\n",
    "        self.d_short = d_short\n",
    "        \n",
    "        self.long0 = nn.Parameter(torch.zeros(d_long))\n",
    "        self.short0 = nn.Parameter(torch.zeros(d_short))\n",
    "        self.i_short = nn.Linear(d_short, d_long, bias=False)\n",
    "        self.i_in = nn.Linear(d_in, d_long)\n",
    "        self.f_short = nn.Linear(d_short, d_long, bias=False)\n",
    "        self.f_in = nn.Linear(d_in, d_long)\n",
    "        self.g_short = nn.Linear(d_short, d_long, bias=False)\n",
    "        self.g_in = nn.Linear(d_in, d_long)\n",
    "        self.o_short = nn.Linear(d_short, d_long, bias=False)\n",
    "        self.o_in = nn.Linear(d_in, d_long)\n",
    "        self.proj = nn.Linear(d_long, d_short)\n",
    "        self.out = nn.Linear(d_long, d_short)\n",
    "\n",
    "        nn.init.ones_(self.f_in.bias)\n",
    "        for bias in [self.i_in.bias, self.g_in.bias, self.o_in.bias, self.proj.bias, self.out.bias]:\n",
    "            nn.init.zeros_(bias)\n",
    "\n",
    "        for weight in [self.i_short.weight, self.f_short.weight, self.g_short.weight, self.o_short.weight, self.proj.weight]:\n",
    "            nn.init.orthogonal_(weight)\n",
    "\n",
    "        for weight in [self.i_in.weight, self.f_in.weight, self.g_in.weight, self.o_in.weight, self.out.weight]:\n",
    "            nn.init.normal_(weight, mean=0.0, std=0.02)\n",
    "            \n",
    "    def forward(self, x, x_len, hiddens = None):\n",
    "        batch_size = x.size(0)\n",
    "        sq_len = x.size(1)\n",
    "        if hiddens == None:\n",
    "            shorts = self.short0.unsqueeze(0).repeat(batch_size, 1)\n",
    "            longs = self.long0.unsqueeze(0).repeat(batch_size, 1)\n",
    "        else:\n",
    "            shorts = hiddens[0]\n",
    "            longs = hiddens[1]\n",
    "            \n",
    "        mask = (torch.arange(sq_len, device=x.device).unsqueeze(0) < x_len.unsqueeze(1)).unsqueeze(-1)\n",
    "        out = torch.zeros(batch_size, sq_len, self.d_short, device=x.device)\n",
    "        for sq_idx in range(sq_len):\n",
    "            i = torch.sigmoid(self.i_short(shorts) + self.i_in(x[:, sq_idx]))\n",
    "            f = torch.sigmoid(self.f_short(shorts) + self.f_in(x[:, sq_idx]))\n",
    "            g = torch.tanh(self.g_short(shorts) + self.g_in(x[:, sq_idx]))\n",
    "            o = torch.sigmoid(self.o_short(shorts) + self.o_in(x[:, sq_idx]))\n",
    "            longs = (f * longs + i * g) * mask[:, sq_idx] + longs * ~mask[:, sq_idx]\n",
    "            shorts = self.proj(o * longs) * mask[:, sq_idx] + shorts * ~mask[:, sq_idx]\n",
    "            out[:, sq_idx] = self.out(o * longs)\n",
    "        return out, (shorts, longs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "731e2563-3f15-4b39-94d2-f577b0849817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-head self attention with RoPE defined in a manner that allows both parallel and auto-regressive computation\n",
    "float_min = torch.finfo(torch.float32).min\n",
    "class MHSA(nn.Module):\n",
    "    def __init__(self, d_model, d_sa, n_head, dropout = 0.1):\n",
    "        super(MHSA, self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        self.d_sa = d_sa\n",
    "        self.d_key = d_sa // n_head\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.rope = torchtune.modules.RotaryPositionalEmbeddings(dim=self.d_key)\n",
    "        \n",
    "        self.q = nn.Linear(d_model, d_sa)\n",
    "        self.k = nn.Linear(d_model, d_sa)\n",
    "        self.v = nn.Linear(d_model, d_sa)\n",
    "        self.sa_lin = nn.Linear(d_sa, d_model)\n",
    "        for lin in [self.k, self.q, self.v, self.sa_lin]:\n",
    "            nn.init.normal_(lin.weight, mean=0.0, std=0.02)\n",
    "            nn.init.zeros_(lin.bias)\n",
    "\n",
    "    def forward(self, x, ks, vs, mask=None, position=None):\n",
    "        # If we are receiving one single element in a sequence rather than a whole sequence,\n",
    "        # we unsqueeze it at the beginning and resqueeze it at the end to make the tensor shapes work out\n",
    "        is_sequence = (len(x.size()) == 3)\n",
    "        if not is_sequence:\n",
    "            x = x.unsqueeze(1)\n",
    "        batch_size = x.size(0)\n",
    "        sq_len = x.size(1)\n",
    "        qs = self.rope(self.q(x).view(batch_size, sq_len, self.n_head, self.d_key), input_pos=position).transpose(1, 2)\n",
    "        dots = torch.matmul(qs, ks.transpose(-1, -2)) / math.sqrt(self.d_key)\n",
    "        if mask != None:\n",
    "            dots[~(mask.unsqueeze(1).repeat(1, self.n_head, 1, 1))] = float_min\n",
    "        attn_weight = self.dropout(nn.Softmax(dim = -1)(dots))\n",
    "        attns = torch.matmul(attn_weight, vs).transpose(1, 2).contiguous().view(batch_size, sq_len, self.d_sa)\n",
    "        if not is_sequence:\n",
    "            attns = attns.squeeze(1)\n",
    "        return self.sa_lin(attns)\n",
    "\n",
    "    # Cacheing keys and values is extremely important for autoregressive generation\n",
    "    # This saves significant computation for recurrent architectures\n",
    "    def cache_kvs(self, x, ks=None, vs=None, position=None):\n",
    "        if len(x.size()) == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        if ks == None:\n",
    "            sq_len = x.size(1)\n",
    "            ks = self.rope(self.k(x).view(batch_size, sq_len, self.n_head, self.d_key)).transpose(1, 2)\n",
    "            vs = self.v(x).view(batch_size, sq_len, self.n_head, self.d_key).transpose(1, 2)\n",
    "            return ks, vs\n",
    "        else:\n",
    "            if x.size(1) != 1:\n",
    "                raise Exception(\"Expected only one sequence element input at a time with auto-regressive kv caching\")\n",
    "            sq_len = ks.size(2)\n",
    "            new_ks = self.rope(self.k(x).view(batch_size, 1, self.n_head, self.d_key), input_pos=position).transpose(1, 2)\n",
    "            new_vs = self.v(x).view(batch_size, 1, self.n_head, self.d_key).transpose(1, 2)\n",
    "            return torch.cat([ks, new_ks], 2), torch.cat([vs, new_vs], 2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7dd37f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base model shell for embeddings, output linear, and calculating loss\n",
    "class Base(nn.Module):\n",
    "    def __init__(self, model, vocab, reuse_embeddings = False, include_x_loss = False):\n",
    "        super(Base, self).__init__()\n",
    "        self.model = model\n",
    "        self.vocab = vocab\n",
    "        self.d_model = model.d_model\n",
    "        self.vocab_len = len(vocab)\n",
    "        self.embedding = nn.Embedding(self.vocab_len, self.d_model)\n",
    "        self.actor = nn.Linear(self.d_model, self.vocab_len, bias=False)\n",
    "        if reuse_embeddings:\n",
    "            self.actor.weight = self.embedding.weight\n",
    "        self.include_x_loss = include_x_loss\n",
    "        self.criteria = nn.CrossEntropyLoss(ignore_index=vocab.index(PAD))\n",
    "\n",
    "        nn.init.normal_(self.embedding.weight, mean=0.0, std=0.02)\n",
    "        nn.init.normal_(self.actor.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    def forward(self, x, x_len, hiddens=None):\n",
    "        if len(x.size()) != 2:\n",
    "            raise Exception(\"Input must be of shape (batch_size, sq_len), received input shape\", x.shape()) \n",
    "        output, hiddens = self.model(self.embedding(x), x_len, hiddens)\n",
    "        return self.actor(output) / (self.d_model ** 0.5), hiddens\n",
    "    \n",
    "    def calcLoss(self, xy, x_len, xy_len):\n",
    "        batch_size = xy.size(0)\n",
    "        sq_len = xy.size(1)\n",
    "        output, _ = self(xy, xy_len)\n",
    "\n",
    "        if self.include_x_loss:\n",
    "            selected = (torch.arange(sq_len, device=xy.device).unsqueeze(0) < xy_len.unsqueeze(1))[:, 1:]\n",
    "        else:\n",
    "            selected = ((torch.arange(sq_len, device=xy.device).unsqueeze(0) < xy_len.unsqueeze(1)) & (torch.arange(sq_len, device=xy.device).unsqueeze(0) >= x_len.unsqueeze(1)))[:, 1:]\n",
    "            \n",
    "        guesses = output[:, :-1][selected]\n",
    "        actual = xy[:, 1:][selected]\n",
    "\n",
    "        return self.criteria(guesses, actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb8b4cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder only transformer architecture, as commonly used in generative pretrained transformers \n",
    "class DecTrans(nn.Module):\n",
    "    def __init__(self, d_model, d_sa, d_ffwd, n_head, n_lay, activ=nn.GELU(), dropout = 0.1):\n",
    "        super(DecTrans, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_sa = d_sa\n",
    "        self.d_ffwd = d_ffwd\n",
    "        self.n_head = n_head\n",
    "        self.n_lay = n_lay\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.sas = nn.ParameterList([MHSA(d_model, d_sa, n_head, dropout=dropout) for _ in range(n_lay)])\n",
    "        self.ffwds = nn.ParameterList([FeedFwd([d_model, d_ffwd, d_model], dropout=dropout, activ=activ) for _ in range(n_lay)])\n",
    "        self.sa_norms = nn.ParameterList([nn.LayerNorm(d_model) for _ in range(n_lay)])\n",
    "        self.ffwd_norms = nn.ParameterList([nn.LayerNorm(d_model) for _ in range(n_lay)])\n",
    "\n",
    "        for norm in self.sa_norms:\n",
    "            nn.init.ones_(norm.weight)\n",
    "            nn.init.zeros_(norm.bias)\n",
    "\n",
    "        for norm in self.ffwd_norms:\n",
    "            nn.init.ones_(norm.weight)\n",
    "            nn.init.zeros_(norm.bias)\n",
    "        \n",
    "    def forward(self, x, x_len, hiddens=None):\n",
    "        batch_size = x.size(0)\n",
    "        sq_len = x.size(1)\n",
    "        if hiddens == None:\n",
    "            ks = [None for _ in range(self.n_lay)]\n",
    "            vs = [None for _ in range(self.n_lay)]\n",
    "            src_mask = (torch.arange(sq_len, device=x.device).unsqueeze(0) < x_len.unsqueeze(1))\n",
    "            mask = src_mask.unsqueeze(1).repeat(1, sq_len, 1) & torch.tril(torch.ones(batch_size, sq_len, sq_len, dtype=torch.bool, device=x.device))\n",
    "            position = None\n",
    "        else:\n",
    "            #TODO, allow sq_len > 1 during generation\n",
    "            if sq_len != 1:\n",
    "                raise Exception(\"Must only enter one sequence element at a time during autoregressive generation\")\n",
    "            ks, vs, src_mask = hiddens\n",
    "            src_mask = torch.cat([src_mask, (torch.arange(sq_len, device=x.device).unsqueeze(0) < x_len.unsqueeze(1))], dim=1)\n",
    "            # We don't need a causality mask when we are autoregressively generating, and when there are hiddens we must be autoregressively generating\n",
    "            mask = src_mask.unsqueeze(1)\n",
    "            position = mask.sum(dim=2) - 1\n",
    "            \n",
    "        for layer in range(self.n_lay):\n",
    "            ks[layer], vs[layer] = self.sas[layer].cache_kvs(x, ks[layer], vs[layer], position)\n",
    "            x = self.sa_norms[layer](x + self.dropout(self.sas[layer](x, ks[layer], vs[layer], mask=mask, position=position)))\n",
    "            x = self.ffwd_norms[layer](x + self.dropout(self.ffwds[layer](x)))\n",
    "        return x, (ks, vs, src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "152b3122-8655-475e-aa85-5ce44562c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple layer LSTM, uses residual connections and layer normalization, like the decoder transformer, but has no self attention\n",
    "class MultiLayLSTM(nn.Module):\n",
    "    def __init__(self, d_model, d_lstm, n_lay, dropout = 0.1):\n",
    "        super(MultiLayLSTM, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_lstm = d_lstm\n",
    "        self.n_lay = n_lay\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.lstms = nn.ParameterList([LSTM(d_model, d_lstm, d_model) for _ in range(n_lay)])\n",
    "        self.norms = nn.ParameterList([nn.LayerNorm(d_model) for _ in range(n_lay)])\n",
    "    \n",
    "    def forward(self, x, x_len, hiddens=None):\n",
    "        batch_size = x.size(0)\n",
    "        if hiddens == None:\n",
    "            hiddens = [None for _ in range(self.n_lay)]\n",
    "\n",
    "        for layer in range(self.n_lay):\n",
    "            lstm_out, hiddens[layer] = self.lstms[layer](x, x_len, hiddens[layer])\n",
    "            x = self.norms[layer](x + self.dropout(lstm_out))\n",
    "            \n",
    "        return x, hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d618512e-e3c8-4858-9b87-2348f3642985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long short term memory transformer, same as decoder transformer except substituting the feed forward network with an LSTM\n",
    "class LSTMTrans(nn.Module):\n",
    "    def __init__(self, d_model, d_sa, d_lstm, n_head, n_lay, activ=nn.GELU(), dropout = 0.1):\n",
    "        super(LSTMTrans, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_sa = d_sa\n",
    "        self.d_lstm = d_lstm\n",
    "        self.n_head = n_head\n",
    "        self.n_lay = n_lay\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.sas = nn.ParameterList([MHSA(d_model, d_sa, n_head, dropout=dropout) for _ in range(n_lay)])\n",
    "        self.lstms = nn.ParameterList([LSTM(d_model, d_lstm, d_model) for _ in range(n_lay)])\n",
    "        self.sa_norms = nn.ParameterList([nn.LayerNorm(d_model) for _ in range(n_lay)])\n",
    "        self.lstm_norms = nn.ParameterList([nn.LayerNorm(d_model) for _ in range(n_lay)])\n",
    "\n",
    "        for norm in self.sa_norms:\n",
    "            nn.init.ones_(norm.weight)\n",
    "            nn.init.zeros_(norm.bias)\n",
    "\n",
    "        for norm in self.lstm_norms:\n",
    "            nn.init.ones_(norm.weight)\n",
    "            nn.init.zeros_(norm.bias)\n",
    "        \n",
    "    def forward(self, x, x_len, hiddens=None):\n",
    "        batch_size = x.size(0)\n",
    "        sq_len = x.size(1)\n",
    "        if hiddens == None:\n",
    "            ks = [None for _ in range(self.n_lay)]\n",
    "            vs = [None for _ in range(self.n_lay)]\n",
    "            src_mask = (torch.arange(sq_len, device=x.device).unsqueeze(0) < x_len.unsqueeze(1))\n",
    "            mask = src_mask.unsqueeze(1).repeat(1, sq_len, 1) & torch.tril(torch.ones(batch_size, sq_len, sq_len, dtype=torch.bool, device=x.device))\n",
    "            position = None\n",
    "            lstm_hiddens = [None for _ in range(self.n_lay)]\n",
    "        else:\n",
    "            #TODO, allow sq_len > 1 during generation\n",
    "            if sq_len != 1:\n",
    "                raise Exception(\"Must only enter one sequence element at a time during autoregressive generation\")\n",
    "            ks, vs, src_mask, lstm_hiddens = hiddens\n",
    "            src_mask = torch.cat([src_mask, (torch.arange(sq_len, device=x.device).unsqueeze(0) < x_len.unsqueeze(1))], dim=1)\n",
    "            # We don't need a causality mask when we are autoregressively generating, and when there are hiddens we must be autoregressively generating\n",
    "            mask = src_mask.unsqueeze(1)\n",
    "            position = mask.sum(dim=2) - 1\n",
    "            \n",
    "        for layer in range(self.n_lay):\n",
    "            ks[layer], vs[layer] = self.sas[layer].cache_kvs(x, ks[layer], vs[layer], position)\n",
    "            x = self.sa_norms[layer](x + self.dropout(self.sas[layer](x, ks[layer], vs[layer], mask=mask, position=position)))\n",
    "            lstm_out, lstm_hiddens[layer] = self.lstms[layer](x, x_len, lstm_hiddens[layer])\n",
    "            x = self.lstm_norms[layer](x + self.dropout(lstm_out))\n",
    "        return x, (ks, vs, src_mask, lstm_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f322fed4-db37-4d12-94aa-ed1e929c00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer with recurrent self attention, same as decoder transformer except derives keys and values from output rather than input\n",
    "class RSATrans(nn.Module):\n",
    "    def __init__(self, d_model, d_sa, d_ffwd, n_head, n_lay, activ=nn.GELU(), dropout = 0.1):\n",
    "        super(RSATrans, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ffwd = d_ffwd\n",
    "        self.d_sa = d_sa\n",
    "        self.n_head = n_head\n",
    "        self.n_lay = n_lay\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.ffwds = nn.ParameterList([FeedFwd([d_model, d_ffwd, d_model], dropout=dropout, activ=activ) for _ in range(n_lay)])\n",
    "        self.sas = nn.ParameterList([MHSA(d_model, d_sa, n_head, dropout=dropout) for _ in range (n_lay)])\n",
    "        \n",
    "        self.sa_h0s = nn.ParameterList([nn.Parameter(torch.zeros(d_model)) for _ in range(n_lay)])\n",
    "        self.sa_norms = nn.ParameterList([nn.LayerNorm(d_model) for _ in range(n_lay)])\n",
    "        self.ffwd_norms = nn.ParameterList([nn.LayerNorm(d_model) for _ in range(n_lay)])\n",
    "\n",
    "        for h0 in self.sa_h0s:\n",
    "            nn.init.normal_(h0, mean=0.0, std=0.02)\n",
    "        \n",
    "        for norm in self.sa_norms:\n",
    "            nn.init.ones_(norm.weight)\n",
    "            nn.init.zeros_(norm.bias)\n",
    "\n",
    "        for norm in self.ffwd_norms:\n",
    "            nn.init.ones_(norm.weight)\n",
    "            nn.init.zeros_(norm.bias)\n",
    "        \n",
    "    def forward(self, x, x_len, hiddens=None):\n",
    "        batch_size = x.size(0)\n",
    "        sq_len = x.size(1)\n",
    "        out = torch.zeros((batch_size, sq_len, self.d_model), device = x.device)\n",
    "        \n",
    "        if hiddens == None:\n",
    "            ks = [None for _ in range(self.n_lay)]\n",
    "            vs = [None for _ in range(self.n_lay)]\n",
    "            for layer in range(self.n_lay):\n",
    "                ks[layer], vs[layer] = self.sas[layer].cache_kvs(self.sa_h0s[layer].unsqueeze(0).repeat(batch_size, 1))\n",
    "            # When no hiddens, our source mask must be one larger in the sq_len dimension in order to accomodate the h0\n",
    "            src_mask = (torch.arange(sq_len + 1, device=x.device).unsqueeze(0) < (x_len + 1).unsqueeze(1))\n",
    "        else:\n",
    "            ks, vs, src_mask, lstm_hiddens = hiddens\n",
    "            src_mask = torch.cat([src_mask, (torch.arange(sq_len, device=x.device).unsqueeze(0) < x_len.unsqueeze(1))], dim=1)\n",
    "        \n",
    "        for sq_idx in range(sq_len):\n",
    "            position = src_mask[:, :(sq_idx - sq_len)].sum(dim=1)\n",
    "            curr = x[:, sq_idx]\n",
    "            for layer in range(self.n_lay):\n",
    "                curr = self.sa_norms[layer](curr + self.dropout(self.sas[layer](curr, ks[layer], vs[layer], mask=src_mask[:, :(sq_idx - sq_len)].unsqueeze(1), position=position)))\n",
    "                curr = self.ffwd_norms[layer](curr + self.dropout(self.ffwds[layer](curr)))\n",
    "                ks[layer], vs[layer] = self.sas[layer].cache_kvs(curr, ks[layer], vs[layer], position)\n",
    "            out[:, sq_idx] = curr\n",
    "        \n",
    "        return out, (ks, vs, src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac589ac9-7307-4dae-a884-ae072dcbbc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent Transformer architecture, utilizes LSTMs and recurrent self attention\n",
    "class ReTrans(nn.Module):\n",
    "    def __init__(self, d_model, d_sa, d_lstm, n_head, n_lay, dropout = 0.1):\n",
    "        super(ReTrans, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_lstm = d_lstm\n",
    "        self.d_sa = d_sa\n",
    "        self.n_head = n_head\n",
    "        self.n_lay = n_lay\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.lstms = nn.ParameterList([LSTM(d_model, d_lstm, d_model) for _ in range(n_lay)])\n",
    "        self.sas = nn.ParameterList([MHSA(d_model, d_sa, n_head, dropout=dropout) for _ in range (n_lay)])\n",
    "        \n",
    "        self.sa_h0s = nn.ParameterList([nn.Parameter(torch.zeros(d_model)) for _ in range(n_lay)])\n",
    "        self.sa_norms = nn.ParameterList([nn.LayerNorm(d_model) for _ in range(n_lay)])\n",
    "        self.lstm_norms = nn.ParameterList([nn.LayerNorm(d_model) for _ in range(n_lay)])\n",
    "\n",
    "        for h0 in self.sa_h0s:\n",
    "            nn.init.normal_(h0, mean=0.0, std=0.02)\n",
    "        \n",
    "        for norm in self.sa_norms:\n",
    "            nn.init.ones_(norm.weight)\n",
    "            nn.init.zeros_(norm.bias)\n",
    "\n",
    "        for norm in self.lstm_norms:\n",
    "            nn.init.ones_(norm.weight)\n",
    "            nn.init.zeros_(norm.bias)\n",
    "        \n",
    "    def forward(self, x, x_len, hiddens=None):\n",
    "        batch_size = x.size(0)\n",
    "        sq_len = x.size(1)\n",
    "        out = torch.zeros((batch_size, sq_len, self.d_model), device = x.device)\n",
    "        \n",
    "        if hiddens == None:\n",
    "            ks = [None for _ in range(self.n_lay)]\n",
    "            vs = [None for _ in range(self.n_lay)]\n",
    "            lstm_hiddens = [None for _ in range(self.n_lay)]\n",
    "            for layer in range(self.n_lay):\n",
    "                ks[layer], vs[layer] = self.sas[layer].cache_kvs(self.sa_h0s[layer].unsqueeze(0).repeat(batch_size, 1))\n",
    "            # When no hiddens, our source mask must be one larger in the sq_len dimension in order to accomodate the h0\n",
    "            src_mask = (torch.arange(sq_len + 1, device=x.device).unsqueeze(0) < (x_len + 1).unsqueeze(1))\n",
    "        else:\n",
    "            ks, vs, src_mask, lstm_hiddens = hiddens\n",
    "            src_mask = torch.cat([src_mask, (torch.arange(sq_len, device=x.device).unsqueeze(0) < x_len.unsqueeze(1))], dim=1)\n",
    "        \n",
    "        for sq_idx in range(sq_len):\n",
    "            position = src_mask[:, :(sq_idx - sq_len)].sum(dim=1)\n",
    "            curr = x[:, sq_idx]\n",
    "            for layer in range(self.n_lay):\n",
    "                curr = self.sa_norms[layer](curr + self.dropout(self.sas[layer](curr, ks[layer], vs[layer], mask=src_mask[:, :(sq_idx - sq_len)].unsqueeze(1), position=position)))\n",
    "                lstm_out, lstm_hiddens[layer] = self.lstms[layer](curr.unsqueeze(1), src_mask[:, (sq_idx - sq_len)], lstm_hiddens[layer])\n",
    "                curr = self.lstm_norms[layer](curr + self.dropout(lstm_out.squeeze(1)))\n",
    "                ks[layer], vs[layer] = self.sas[layer].cache_kvs(curr, ks[layer], vs[layer], position)\n",
    "            out[:, sq_idx] = curr\n",
    "        \n",
    "        return out, (ks, vs, src_mask, lstm_hiddens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983bc756-8161-4316-82d6-e3bc3a998145",
   "metadata": {},
   "source": [
    "# Training + Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f01f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different schedulers, we only end up using linear,\n",
    "# But decay and cosine are included in case \n",
    "def decay_scheduler(steps):\n",
    "    warmup_steps = steps // 10\n",
    "    decay = 0.05 ** (1 / (steps - warmup_steps))\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return current_step / warmup_steps\n",
    "        return decay ** (current_step - warmup_steps)\n",
    "    return lr_lambda\n",
    "\n",
    "def cosine_scheduler(steps):\n",
    "    warmup_steps = steps // 10\n",
    "    min_lr = 0.05\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return current_step / warmup_steps\n",
    "        return min_lr + (1 - min_lr) / 2 * (1 + math.cos((current_step - warmup_steps) * math.pi / (steps - warmup_steps)))\n",
    "    return lr_lambda\n",
    "\n",
    "def linear_scheduler(steps):\n",
    "    warmup_steps = steps // 10\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return current_step / warmup_steps\n",
    "        return 1.0 - ((current_step - warmup_steps) / (steps - warmup_steps))\n",
    "    return lr_lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30c30285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function, learning rate scheduling is done on a batch basis instead of epoch, revert to best model\n",
    "def train(model, trainset, validset, lr=0.001, batch_size=512, epochs=10, optimizer=torch.optim.AdamW, scheduler=cosine_scheduler):\n",
    "    train_iter = DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    valid_iter = DataLoader(validset, batch_size=batch_size, pin_memory=True)\n",
    "    optim = optimizer(model.parameters(), lr=lr)\n",
    "    lambdalr = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=scheduler(epochs * len(train_iter)))\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, batch in enumerate(train_iter):\n",
    "            xy, x_len, xy_len = batch\n",
    "            print('=' * (math.floor((batch_idx / len(train_iter)) * 40) - math.floor(((batch_idx - 1) / len(train_iter)) * 40)), end = \"\")\n",
    "            optim.zero_grad()\n",
    "            loss = model.calcLoss(xy.to(device), x_len.to(device), xy_len.to(device))\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            lambdalr.step()\n",
    "        print(\">\\nEpoch {} train loss:\\t{}\".format(epoch, train_loss / len(train_iter)))\n",
    "        train_losses.append(train_loss / len(train_iter))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss = 0\n",
    "            for batch in valid_iter:\n",
    "                xy, x_len, xy_len = batch\n",
    "                loss = model.calcLoss(xy.to(device), x_len.to(device), xy_len.to(device))\n",
    "                valid_loss += loss.item()\n",
    "        print(\"Epoch {} valid loss:\\t{}\".format(epoch, valid_loss / len(valid_iter)))\n",
    "        valid_losses.append(valid_loss / len(valid_iter))\n",
    "        \n",
    "        if valid_losses[-1] == min(valid_losses):\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "    os.remove('best_model.pth')\n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3f95ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests what proportion of the test set that the model predicts in one shot\n",
    "@torch.no_grad()\n",
    "def test(model, testset, batch_size=512):\n",
    "    test_iter = DataLoader(testset, batch_size=batch_size, pin_memory=True)\n",
    "    num_correct = 0\n",
    "    model.eval()\n",
    "    for batch in test_iter:\n",
    "        xy, x_len, xy_len = batch\n",
    "        xy = xy.to(device)\n",
    "        x_len = x_len.to(device)\n",
    "        xy_len = xy_len.to(device)\n",
    "        out, _ = model(xy, xy_len)\n",
    "        guesses = torch.argmax(out[:, :-1], dim=-1)\n",
    "        answer_selector = ((torch.arange(xy.size(1), device=device).unsqueeze(0) < xy_len.unsqueeze(1)) & (torch.arange(xy.size(1), device=device).unsqueeze(0) >= x_len.unsqueeze(1))).to(device)[:, 1:]\n",
    "        correct_token = (guesses == xy[:, 1:]) & answer_selector\n",
    "        correct_answer = (correct_token.sum(dim=1) == (xy_len - x_len))\n",
    "        num_correct += torch.sum(correct_answer).item()\n",
    "    return num_correct / len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f4aa0c8-2af1-410f-8afe-05ded4bddb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the output for an input\n",
    "@torch.no_grad()\n",
    "def solve(model, x, x_len, vocab, max_y_len):\n",
    "    batch_size = x.size(0)\n",
    "    stop_idx = vocab.index(STOP)\n",
    "    y = torch.zeros(batch_size, max_y_len, dtype=torch.long, device=x.device)\n",
    "    y_len = torch.full((batch_size,), max_y_len, device=x.device)\n",
    "    model.eval()\n",
    "    out, hiddens = model(x, x_len)\n",
    "    y[:, 0] = torch.argmax(out[torch.arange(batch_size, device=x.device), x_len - 1], dim=1)\n",
    "    for i in range(max_y_len - 1):\n",
    "        y_len[(y[:, i] == stop_idx) & (y_len == max_y_len)] = i\n",
    "        out, hiddens = model(y[:, i].unsqueeze(1), (y_len == max_y_len), hiddens)\n",
    "        y[:, i + 1] = torch.argmax(out[:, 0], dim=1)\n",
    "    return y, y_len + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e50add2",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f92fbc05-5d97-4a22-91b0-1cabec2c7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(datasets, model_type, model_args, train_args={}, test_args={}):\n",
    "    trainset, validset, testset = datasets\n",
    "    experimental_results = {}\n",
    "    if str(device) == \"cpu\":\n",
    "        experimental_results[\"device\"] = \"cpu\"\n",
    "    else:\n",
    "        experimental_results[\"device\"] = torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "    experimental_results[\"model class\"] = model_type.__name__\n",
    "    experimental_results[\"dataset class\"] = trainset.dataset.__class__.__name__\n",
    "    experimental_results[\"dataset sizes\"] = (len(trainset), len(validset), len(testset))\n",
    "    model = Base(model_type(**model_args), trainset.dataset.vocab).to(device)\n",
    "    experimental_results[\"model args\"] = model_args\n",
    "    experimental_results[\"model size\"] = sum(p.numel() for p in model.model.parameters() if p.requires_grad)\n",
    "    print(\"Parameter count\", experimental_results[\"model size\"])\n",
    "    flop_xy, flop_x_len, flop_xy_len = next(iter(DataLoader(testset, batch_size=64)))\n",
    "    # Note this does not catch all operations, but it catches matmul, which is by far the dominant operator\n",
    "    flops = FlopCountAnalysis(model, (flop_xy.to(device), flop_xy_len.to(device)))\n",
    "    experimental_results[\"flops per input\"] = flops.total() // 64\n",
    "    print(\"Flops per input\", experimental_results[\"flops per input\"])\n",
    "    experimental_results[\"train args\"] = train_args\n",
    "    start_time = time.perf_counter()\n",
    "    train_loss, valid_loss = train(model, trainset, validset, **train_args)\n",
    "    end_time = time.perf_counter()\n",
    "    experimental_results[\"train loss\"] = train_loss\n",
    "    experimental_results[\"valid loss\"] = valid_loss\n",
    "    experimental_results[\"train time\"] = end_time - start_time\n",
    "    print(\"Train time\", experimental_results[\"train time\"])\n",
    "    experimental_results[\"test args\"] = test_args\n",
    "    experimental_results[\"test accuracy\"] = test(model, testset, **test_args)\n",
    "    print(\"Test accuracy\", experimental_results[\"test accuracy\"])\n",
    "    return experimental_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20eec259-e797-4f92-8b9a-fe435d8442c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_experiment(experiment_dict, name=None):\n",
    "    if not os.path.exists(\"experiments\"):\n",
    "        os.makedirs(\"experiments\")\n",
    "    if name == None:\n",
    "        name = time.ctime()\n",
    "    try:\n",
    "        with open(f\"experiments/{time.perf_counter() if name == None else name}.json\", \"w\") as f:\n",
    "            json.dump(experiment_dict, f, indent=4, default=lambda x: x.__name__)\n",
    "        print(f\"Experiment {name} saved\")\n",
    "    except:\n",
    "        print(f\"Failure saving experiment {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ebf88ec-c812-4b81-acd7-69127428663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_experiments():\n",
    "    experiments = []\n",
    "    if not os.path.exists(\"experiments\"):\n",
    "        print(\"No experiments directory\")\n",
    "    else:\n",
    "        for file in os.listdir(\"experiments\"):\n",
    "            try:\n",
    "                with open(f\"experiments/{file}\", \"r\") as f:\n",
    "                    experiments.append(json.load(f))\n",
    "            except:\n",
    "                print(\"Error loading json experiment:\", file)\n",
    "    return experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8320867-9eb8-46ae-9d69-b526437075a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter count 729088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::embedding encountered 1 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::repeat encountered 164 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mul encountered 2448 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sub encountered 308 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add encountered 1678 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::lt encountered 153 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::rsub encountered 342 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sum encountered 38 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::div encountered 153 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::softmax encountered 152 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sigmoid encountered 456 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::tanh encountered 152 time(s)\n",
      "WARNING:fvcore.nn.jit_analysis:The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "criteria\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flops per input 27954560\n",
      "========================================>\n",
      "Epoch 0 train loss:\t1.7162065160274507\n",
      "Epoch 0 valid loss:\t0.949542740881443\n",
      "========================================>\n",
      "Epoch 1 train loss:\t0.8025395053625107\n",
      "Epoch 1 valid loss:\t0.6668105074763298\n",
      "========================================>\n",
      "Epoch 2 train loss:\t0.6167759650945663\n",
      "Epoch 2 valid loss:\t0.5410297358036041\n",
      "========================================>\n",
      "Epoch 3 train loss:\t0.5311480776071549\n",
      "Epoch 3 valid loss:\t0.484632733464241\n",
      "========================================>\n",
      "Epoch 4 train loss:\t0.4708712833225727\n",
      "Epoch 4 valid loss:\t0.4404362453520298\n",
      "========================================>\n",
      "Epoch 5 train loss:\t0.42551880738139153\n",
      "Epoch 5 valid loss:\t0.4018432502448559\n",
      "========================================>\n",
      "Epoch 6 train loss:\t0.38846165645122527\n",
      "Epoch 6 valid loss:\t0.367625647932291\n",
      "========================================>\n",
      "Epoch 7 train loss:\t0.3517845411002636\n",
      "Epoch 7 valid loss:\t0.3433664847910404\n",
      "========================================>\n",
      "Epoch 8 train loss:\t0.32676662078499796\n",
      "Epoch 8 valid loss:\t0.3300132678449154\n",
      "========================================>\n",
      "Epoch 9 train loss:\t0.31128363019227984\n",
      "Epoch 9 valid loss:\t0.3250736986845732\n",
      "Train time 8664.736939481998\n",
      "Test accuracy 0.71091796875\n",
      "Experiment Sat Jul  5 07:18:33 2025 saved\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "write_experiment(experiment(arithSets, ReTrans, \\\n",
    "                            model_args={\"d_model\":64, \"d_sa\":64, \"d_lstm\":256, \"n_head\":8, \"n_lay\":4}, \\\n",
    "                            train_args={\"lr\":0.003, \"batch_size\":512, \"epochs\":10}, \\\n",
    "                            test_args={\"batch_size\":512}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167d087-39e6-4801-ae0b-8175cdeabf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
